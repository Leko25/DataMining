{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/Users/chukuemekaogudu/Documents/Dev-Spark-Apache/Apache-Spark/spark-2.4.5-bin-hadoop2.7\")\n",
    "import os\n",
    "import json\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from datetime import datetime\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Volumes/oli2/inf533_datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"Task1\")\n",
    "sc = SparkContext(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadStopWords():\n",
    "    data = None\n",
    "    with open(os.path.join(data_dir, \"stopwords\"), \"rb\") as file:\n",
    "        data = file.read()\n",
    "    return data.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapJsonObj(jsonObj):\n",
    "    year = datetime.strptime(jsonObj[\"date\"], \"%Y-%m-%d %H:%M:%S\").year\n",
    "    return ((year, 1), (jsonObj[\"user_id\"], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile(os.path.join(data_dir, \"review.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = lines.map(json.loads) \\\n",
    "                    .map(lambda x: mapJsonObj(x)) \\\n",
    "                    .partitionBy(10, lambda x: hash(x)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_y = rdd.filter(lambda x: x[0][0] == 2017) \\\n",
    "               .map(lambda x: x[0]).reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reviews = rdd.map(lambda x: x[1]) \\\n",
    "                  .reduceByKey(lambda x, y: x + y) \\\n",
    "                  .sortBy(lambda x: x[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time  2.391263008117676\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "total_reviews = rdd.count()\n",
    "unique_users = rdd.map(lambda x: x[1][0]).distinct().count()\n",
    "top_users = user_reviews.take(10)\n",
    "end = time.time()\n",
    "print(\"Time \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CxDOIDnH8gp9KXzpBHJYXw', 715),\n",
       " ('bLbSNkLggFnqwNNzzq-Ijw', 424),\n",
       " ('PKEzKWv_FktMm2mGPjwd0Q', 322),\n",
       " ('DK57YibC5ShBmqQl97CKog', 291),\n",
       " ('ELcQDlf69kb-ihJfxZyL0A', 288),\n",
       " ('U4INQZOPSUaj8hMjLlZ3KA', 276),\n",
       " ('QJI9OSEn6ujRCtrX06vs1w', 258),\n",
       " ('d_TBs6J3twMy9GChqUEXkg', 253),\n",
       " ('hWDybu_KvYLSdEFzGrniTw', 239),\n",
       " ('dIIKEfOgo0KqUfGQvGikPg', 216)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[5] at mapPartitions at PythonRDD.scala:133"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = loadStopWords().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lines = sc.textFile(os.path.join(data_dir, \"review.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPunctuation(jsonObj):\n",
    "    words = jsonObj[\"text\"].translate(str.maketrans('', '', string.punctuation))\n",
    "    words = words.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterWords(word):\n",
    "    pattern = \"[a-zA-Z]+\"\n",
    "    if re.match(pattern, word) and word not in stopwords:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd = text_lines.flatMap(lambda x: filterPunctuation(json.loads(x))) \\\n",
    "                     .map(lambda x: (x.lower(), 1)) \\\n",
    "                     .filter(lambda x: filterWords(x[0])).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "top_words = text_rdd.reduceByKey(lambda x, y: x + y) \\\n",
    "                    .sortBy(lambda x: x[1], ascending=False)\n",
    "end = time.time()\n",
    "print(\"Time \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time  0.5254449844360352\n"
     ]
    }
   ],
   "source": [
    "results = top_words.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('food', 576209),\n",
       " ('place', 560373),\n",
       " ('good', 560111),\n",
       " ('great', 498172),\n",
       " ('service', 417863),\n",
       " ('like', 405253),\n",
       " ('time', 398821),\n",
       " ('get', 385094),\n",
       " ('one', 377153),\n",
       " ('would', 353381)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
