{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/Users/chukuemekaogudu/Documents/Dev-Spark-Apache/Apache-Spark/spark-2.4.5-bin-hadoop2.7\")\n",
    "import os\n",
    "import json\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import datetime\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Volumes/oli2/inf533_datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"Task1\")\n",
    "sc = SparkContext(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadStopWords():\n",
    "    data = None\n",
    "    with open(os.path.join(data_dir, \"stopwords\"), \"rb\") as file:\n",
    "        data = file.read()\n",
    "    return data.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = loadStopWords().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "me\n",
      "my\n",
      "myself\n",
      "we\n",
      "our\n",
      "ours\n",
      "ourselves\n",
      "you\n",
      "your\n",
      "yours\n",
      "yourself\n",
      "yourselves\n",
      "he\n",
      "him\n",
      "his\n",
      "himself\n",
      "she\n",
      "her\n",
      "hers\n",
      "herself\n",
      "it\n",
      "its\n",
      "itself\n",
      "they\n",
      "them\n",
      "their\n",
      "theirs\n",
      "themselves\n",
      "what\n",
      "which\n",
      "who\n",
      "whom\n",
      "this\n",
      "that\n",
      "these\n",
      "those\n",
      "am\n",
      "is\n",
      "are\n",
      "was\n",
      "were\n",
      "be\n",
      "been\n",
      "being\n",
      "have\n",
      "has\n",
      "had\n",
      "having\n",
      "do\n",
      "does\n",
      "did\n",
      "doing\n",
      "a\n",
      "an\n",
      "the\n",
      "and\n",
      "but\n",
      "if\n",
      "or\n",
      "because\n",
      "as\n",
      "until\n",
      "while\n",
      "of\n",
      "at\n",
      "by\n",
      "for\n",
      "with\n",
      "about\n",
      "against\n",
      "between\n",
      "into\n",
      "through\n",
      "during\n",
      "before\n",
      "after\n",
      "above\n",
      "below\n",
      "to\n",
      "from\n",
      "up\n",
      "down\n",
      "in\n",
      "out\n",
      "on\n",
      "off\n",
      "over\n",
      "under\n",
      "again\n",
      "further\n",
      "then\n",
      "once\n",
      "here\n",
      "there\n",
      "when\n",
      "where\n",
      "why\n",
      "how\n",
      "all\n",
      "any\n",
      "both\n",
      "each\n",
      "few\n",
      "more\n",
      "most\n",
      "other\n",
      "some\n",
      "such\n",
      "no\n",
      "nor\n",
      "not\n",
      "only\n",
      "own\n",
      "same\n",
      "so\n",
      "than\n",
      "too\n",
      "very\n",
      "s\n",
      "t\n",
      "can\n",
      "will\n",
      "just\n",
      "don\n",
      "should\n",
      "now\n"
     ]
    }
   ],
   "source": [
    "for word in stopwords:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapJsonObj(jsonObj):\n",
    "    year = datetime.datetime.strptime(jsonObj[\"date\"], \"%Y-%m-%d %H:%M:%S\").year\n",
    "    \n",
    "    words = jsonObj[\"text\"].translate(str.maketrans('', '', string.punctuation))\n",
    "    words = words.split()\n",
    "    pattern = \"[a-zA-Z]+\"\n",
    "    \n",
    "    words_dict = {}\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if re.match(pattern, word) and word not in stopwords:\n",
    "            if word not in words_dict:\n",
    "                words_dict[word] = 1\n",
    "            else:\n",
    "                words_dict[word] += 1\n",
    "    words_list = list(words_dict.items())\n",
    "    return (\n",
    "        (year, 1), \n",
    "        (jsonObj[\"review_id\"], 1), \n",
    "        (jsonObj[\"user_id\"], 1),\n",
    "        words_list,\n",
    "    )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile(os.path.join(data_dir, \"review.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = lines.map(json.loads).map(lambda x: mapJsonObj(x)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2017, 1), ('-I5umRTkhw15RqpKMl_o1Q', 1), ('-mA3-1mN4JIEkqOtdbNXCQ', 1), [('walked', 4), ('around', 1), ('friday', 1), ('afternoon', 1), ('sat', 1), ('table', 1), ('bar', 2), ('min', 1), ('dont', 1), ('even', 1), ('think', 1), ('realized', 1), ('however', 1), ('everyone', 1), ('noticed', 1), ('service', 1), ('non', 1), ('existent', 1), ('best', 1), ('good', 1), ('way', 1), ('new', 1), ('business', 1), ('start', 1), ('oh', 1), ('well', 1), ('location', 1), ('different', 1), ('things', 1), ('past', 1), ('several', 1), ('years', 1), ('added', 1), ('list', 1), ('smdh', 1)])\n"
     ]
    }
   ],
   "source": [
    "vals = rdd.take(1)\n",
    "for val in vals:\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151625\n"
     ]
    }
   ],
   "source": [
    "total_reviews = rdd.count()\n",
    "print(total_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_y = rdd.map(lambda x: x[0]) \\\n",
    "                .filter(lambda x: x[0] == 2017) \\\n",
    "                .reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2017, 209995)]\n"
     ]
    }
   ],
   "source": [
    "print(reviews_y.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566269\n"
     ]
    }
   ],
   "source": [
    "unique_users = rdd.map(lambda x: x[2][0]).distinct().count()\n",
    "print(unique_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CxDOIDnH8gp9KXzpBHJYXw', 715), ('bLbSNkLggFnqwNNzzq-Ijw', 424), ('PKEzKWv_FktMm2mGPjwd0Q', 322), ('DK57YibC5ShBmqQl97CKog', 291), ('ELcQDlf69kb-ihJfxZyL0A', 288), ('U4INQZOPSUaj8hMjLlZ3KA', 276), ('QJI9OSEn6ujRCtrX06vs1w', 258), ('d_TBs6J3twMy9GChqUEXkg', 253), ('hWDybu_KvYLSdEFzGrniTw', 239), ('dIIKEfOgo0KqUfGQvGikPg', 216)]\n"
     ]
    }
   ],
   "source": [
    "user_reviews = rdd.map(lambda x: x[2]) \\\n",
    "                  .reduceByKey(lambda x, y: x + y) \\\n",
    "                  .sortBy(lambda x: x[1], ascending=False)\n",
    "print(user_reviews.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('food', 576209), ('place', 560373), ('good', 560111), ('great', 498172), ('service', 417863), ('like', 405253), ('time', 398821), ('get', 385094), ('one', 377153), ('would', 353381)]\n"
     ]
    }
   ],
   "source": [
    "top_words = rdd.map(lambda x: x[3]) \\\n",
    "               .flatMap(lambda x: x) \\\n",
    "               .reduceByKey(lambda x, y: x + y) \\\n",
    "               .sortBy(lambda x: x[1], ascending=False)\n",
    "print(top_words.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
